{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYJbuF7FLd4Rmv3UV5ZFDN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaehyun-shin/lanchain_tutorials/blob/main/Langchain_tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 개발환경 세팅"
      ],
      "metadata": {
        "id": "V7tNMFFOuxtk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cH0ynBCDswgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41694771-94a1-4f6c-d127-be8a5bfacc39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.65)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.30.5)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (23.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.2.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "pip install langchain langchain-openai langchain_core"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 환경변수 설정"
      ],
      "metadata": {
        "id": "qVuOVyNSvovR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = userdata.get(\"LANGCHAIN_TRACING_V2\")\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "LLM_MODEL = \"gpt-3.5-turbo\""
      ],
      "metadata": {
        "id": "VQ74NTDSu57v"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 언어 모델 설정\n",
        "모델을 직접 사용합니다. ChatModel은 Langchain의 \"Runnables\"의 인스턴스입니다.\n",
        "상호작요을 위한 표준 인터페이스이지요.\n",
        "모델에 메시지를 넣고 실행을 하기위한 메소드는 `.invoke` 입니다."
      ],
      "metadata": {
        "id": "Fdf3sIoYwbz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=LLM_MODEL)"
      ],
      "metadata": {
        "id": "Yo_7rVjcwbis"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 사용"
      ],
      "metadata": {
        "id": "J5vgODQsw2MR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Message\n",
        "LLM을 통해 대화하려면 messages를 활용해야 합니다.\n",
        "\n",
        "`SystemMessage`의 경우 LLM의 기본 배경(`prompt`) 설정 및 LLM이 어떤 역할이고 어떠한 작업을 하는지 명시할 수 있습니다.\n",
        "\n",
        "`HummanMessage`의 경우 유저가 직접 LLM에게 입력하는 자연어 대화입니다. 이를 통해 LLM에게 질의 할 수 있습니다.\n",
        "\n",
        "LLM 모델의 답변은 `AIMessage`로 응답합니다."
      ],
      "metadata": {
        "id": "-s3CbET3xnpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate to Korean\"),\n",
        "    HumanMessage(content=\"this is langchain tutorial. let's build a simple LLM Application\")\n",
        "]\n",
        "\n",
        "model.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONbcSQ2Gwfwt",
        "outputId": "e7d46bad-91a9-4e26-d106-45d01ece1eb8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='이것은 Langchain 튜토리얼입니다. 간단한 LLM 애플리케이션을 만들어 봅시다.', response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 28, 'total_tokens': 72}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0ba5a431-8f6c-4985-a311-9e4d7a351d87-0', usage_metadata={'input_tokens': 28, 'output_tokens': 44, 'total_tokens': 72})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OutputParsers\n",
        "OutputParser는 모델의 응답을 구문 분석하여 반환합니다."
      ],
      "metadata": {
        "id": "1xO3bcUcxeja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "result = model.invoke(messages)\n",
        "parser.invoke(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SWt9qjbjw8Ak",
        "outputId": "d45c3d49-c528-498d-9429-0fc5764923fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'이것은 Langchain 튜토리얼입니다. 간단한 LLM 애플리케이션을 만들어 봅시다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain\n",
        "OutputParser와 Model을 연결할 수 있습니다. 즉 모델과 출력을 연결해 놓은 chain을 구동시키면 자동으로 결과가 구문 분석으로 반환된 값이 반환됩니다."
      ],
      "metadata": {
        "id": "7ilujPWdyBUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = model | parser\n",
        "\n",
        "chain.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yVaZm1C0xzOX",
        "outputId": "e2831443-89ff-4537-f3d3-6c24a37c9b99"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'이것은 Langchain 튜토리얼입니다. 간단한 LLM 애플리케이션을 만들어 봅시다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prompt\n",
        "메시지의 목록은 일반적으로 사용자의 입력과 애플리케이션 로직의 조합으로 구성됩니다. 미리 작성해둔\n",
        "\n",
        "SystemMessage로 LLM의 역할을 정의하고 사용자의 입력(HumanMessage)에 대응해 답변을 내놓았습니다.\n",
        "\n",
        "하지만 한국어로 변환하는 것이 아닌 다른 언어로 번역하고 싶은 경우 우리는 SystemMessage를 다시 손봐야합니다.\n",
        "\n",
        "따라서 번역할 언어 부분을 변수로 빼놓아 동적으로 만들어야 합니다.\n",
        "\n",
        "PromptTemplate은 이러한 변환을 지원하도록 설계된 Langchain의 개념입니다."
      ],
      "metadata": {
        "id": "VhykC2tFzspH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Translate to {language}: \"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_template),\n",
        "        (\"user\", \"{text}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "result = prompt_template.invoke({\"language\": \"korean\", \"text\": \"this is langchain tutorial. let's build a simple LLM Application\"})\n",
        "\n",
        "print(result.to_messages())\n",
        "\n",
        "# chain에 결합\n",
        "\n",
        "chain = prompt_template | model | parser\n",
        "\n",
        "chain.invoke({\"language\": \"korean\", \"text\": \"hi\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8cFYFiHdyntM",
        "outputId": "d2cddac9-dbac-4fd0-a896-0a7d231a46fb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SystemMessage(content='Translate to korean: '), HumanMessage(content=\"this is langchain tutorial. let's build a simple LLM Application\")]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕하세요'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이로서 간단한 챗 어플리케이션 chain을 구축하였습니다."
      ],
      "metadata": {
        "id": "PnEel84e5jOZ"
      }
    }
  ]
}
